TODO:
* The authors should explain, briefly, where the expected frequency for negative binomial models comes from.
* This should state that the plant was nested within the site, right? And why did they not include "site" as a random effect for the main model described at lines 170-171?  
* Lines 217-219: Please clarify whether this comparison is between the moldy + water vs. the non-moldy + water treatment. Also, here and below, P-values from lme4 should be accompanied by the chi-square value from the model, plus degrees of freedom.
* They have seven different treatments and 3 plants per treatment and site (Lines 117-119). Interestingly, they found that study site effect is zero and conclude that there is not a significant effect. However, this results could be indicating too few data instead. You should check random coefficient (i.e. treatment effects) per site and discuss the variance components.

# Set up the workspace

```{r, message=FALSE}
set.seed(1)
library(lme4)      # For model fitting
library(tidyverse)
library(mixtools)  # For bivariate Gaussian ellipses

d = read.csv("Meiners_BeeHoneydew_data.csv")
```

# Look for seasonal effects

No clear directional trend in bee count over the course of the field season, 
after accounting for time of day.
```{r}
summary(glmer.nb(Bee_Count ~ julDate + scale(min_day) + (1|Plant_Code), data = d))
```

This suggests that most of the variance across days is due to day-specific
factors (such as recent weather) rather than a seasonal effect, and is best
represented by drawing days from a distribution with a random effect (rather 
than imposing a linear shift in bee abundance over the course of the season)

# Core model formulas

We will be focusing on models that include all of the treatment effects,
and on models that omit the sugar effect.

```{r}
raw_formula = "Bee_Count ~ Mold * Insecticide + 
                           Sugar * Paint + 
                           scale(min_day) + 
                           Site +
                           (1|Plant_Code) + 
                           (1|julDate)"

formula = as.formula(raw_formula)

# Drop "Sugar" and the asterisk from the formula
no_sugar_formula = as.formula(
  gsub("Sugar \\* ", "", raw_formula)
)

print(no_sugar_formula)
```

# Model fitting

We modeled the bee counts with negative binomial and Poisson mixed models.

```{r}
# Some versions of the model only reach the maximum-likelihood
# estimate without warnings when we use this optimizer
control = glmerControl(optimizer = "bobyqa")

Honeydew <- glmer.nb(
  formula,
  data=d,
  control = control
)


Honeydew_poisson <- glmer(
  formula,
  data=d,
  family = poisson,
  control = control
)

Honeydew_no_sugar <- glmer.nb(
  no_sugar_formula,
  data=d,
  control = control
)
```

# Model comparison

Which elements of the models fit above are essential? See what happens to model
performance (AIC) when various degrees of freedom are removed from the 
full `Honeydew` negative binomial model.

```{r}
# Drop predictors from the model & reformat the output for
# subsequent work (e.g. removing headings, renaming columns).
# When `drop` says the number of degrees of freedom is NA, it actually 
# means zero, so replace the NAs.
# If the model in `x` is already simplified, then report a larger
# reduction in degrees-of-freedom.
make_dropped_df = function(x, distribution, n_fewer_df = 0){
  drop1(x) %>% 
    structure(heading = NULL) %>% 
    rownames_to_column(var = "dropped") %>% 
    cbind(distribution = distribution) %>% 
    mutate(Df = ifelse(is.na(Df), 0, Df)) %>% 
    mutate(Df = Df + n_fewer_df) %>% 
    rename_(`df reduction` = "Df")
}

# Use the above function on both of the full models, then manually add
# a row for the no_sugar model.
# Finally, eliminate "<" and ">" to prevent formatting errors
initial_dropped_df = rbind(make_dropped_df(Honeydew, "Negative Binomial", 0), 
                           make_dropped_df(Honeydew_poisson, "Poisson", 1)) %>% 
  rbind(data_frame(dropped = "Sugar", `df reduction` = 2, 
                   AIC = AIC(Honeydew_no_sugar), 
                   distribution = "Negative Binomial")) %>% 
  mutate(dropped = gsub("[\\<\\>]", "", dropped))
```

Omitting site or either of the interaction terms (lines 1, 2, 4 and 5) produces 
a relatively small change in AIC, compared with the full model (line 3). However,
none of the models without overdispersion (i.e. the Poisson-distributed models)
had any appreciable AIC weight, nor did the model that removed all sugar effects 
(line 10).

```{r}
# Sort, calculate ΔAIC & AIC weights, format for printing with 
# reasonable precision
initial_dropped_df %>% 
  arrange(AIC) %>% 
  mutate(`ΔAIC` = AIC - AIC[1]) %>% 
  select(-AIC) %>% 
  mutate(`AIC weight (%)` = 100 * exp(-`ΔAIC` / 2) / sum(exp(-`ΔAIC` / 2))) %>% 
  cbind(` `=1:nrow(.), .) %>% 
  knitr::kable(digits = c(rep(1, 4), 2, 1), align = c("llclrr"))
```

$\chi^2$ tests show the same result: omitting sugar effects or overdispersion
significantly reduces model performance (P < .000001).
```{r}
anova(Honeydew, Honeydew_no_sugar)
anova(Honeydew, Honeydew_poisson)
```


# Description of the full `Honeydew` model
```{r}
summary(Honeydew, correlation = FALSE)
anova(Honeydew)
```

# Code for Figure 3

```{r, fig.height=6, fig.width=6}
# Indicator for, "was experimental manipulation i applied to treatment j?""
Mold =        c(1, 1, 0, 0, 0, 0, 0)
Insecticide = c(0, 1, 0, 1, 0, 0, 0)
Sugar =       c(0, 0, 0, 0, 0, 1, 1)
Paint =       c(0, 0, 0, 0, 1, 0, 1)

treat_names = c("Natural Mold", "Natural Mold + Insecticide", "Control", 
                "Insecticide", "Black Paint", "Sugar", "Sugar + Black Paint")

newdata = cbind(
  `(Intercept)` = 1,
  Mold = Mold,
  Insecticide = Insecticide,
  Sugar = Sugar,
  Paint = Paint,
  `scale(min_day)` = 0,
  SiteB = 0,
  SiteC = 0,
  `Mold:Insecticide` = Mold * Insecticide,
  `Sugar:Paint` = Sugar * Paint
)
row.names(newdata) = treat_names

parameter_mu = fixef(Honeydew)
parameter_sigma = as.matrix(vcov(Honeydew))


posterior_samples = MASS::mvrnorm(1E5, parameter_mu, parameter_sigma) %*% t(newdata)

mu = colMeans(posterior_samples)

variances = diag(cov(posterior_samples))
covariance_with_control = cov(posterior_samples)["Control", ]

make_covariance_matrix = function(variance, covariance){
  matrix(c(variance, covariance, covariance, variance), 2)
}

plot_covariances = mapply(make_covariance_matrix, variances, covariance_with_control, SIMPLIFY = FALSE)

control_mu = mu["Control"]
mold_mu = mu["Natural Mold"]
add_ellipse = function(x, mu, sigma, color){
    ellipse(c(x, mu), sigma, col = color)
}

palette = dichromat::colorschemes$Categorical.12[c(2, 12)]
colors = c(palette[1], alpha("gray30", c(1, 0, 1, 1)), rep(palette[2], 2))

plot(NULL, xlim = c(log(.001), log(1)), ylim = c(log(.01), log(10)), asp = 1, axes = FALSE,
     xlab = "Mean bees per control plant", ylab = "Mean bees per treated plant", xaxs = "i", yaxs = "i")
axis(1, log(10^(seq(-10, 10))), 10^(seq(-10, 10)))
axis(2, log(10^(seq(-10, 10))), 10^(seq(-10, 10)))

pwalk(list(x = control_mu, mu = mu, sigma = plot_covariances, color = colors),
      add_ellipse)
text(log(.04), mu * 1.2, treat_names, pos = 2, col = colors)

# 1:1 line
abline(0, 1)
text(log(.02), log(.02), "treatment = control", pos = 2)

```

# Post-hoc comparisons between specific treatment pairs

```{r}
# # P-value for "Sugar effect > Mold effect"
# mean(coef_samples[,"Mold"] > coef_samples[,"Sugar"])
# 
# # P-value for "Sugar+Paint effect < Sugar effect"
# mean(coef_samples[,"Sugar"] + coef_samples[,"Paint"] + coef_samples[,"Sugar:Paint"] > coef_samples[,"Sugar"])
```

