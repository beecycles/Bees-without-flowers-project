---
title: "Appendix for 'Bees Without Flowers'"
output: 
  html_document:
    keep_md: true
    toc: true
    number_sections: true
  pdf_document:
    toc: true
    number_sections: true
---

# Set up the workspace

```{r, message=FALSE}
set.seed(1)
library(lme4)      # For model fitting
library(tidyverse) # For data processing
library(mvtnorm)   # for multivariate Gaussians

# hours_noon represents the amount of time since noon (or until noon, if
# the value is negative)
d = read.csv("Meiners_BeeHoneydew_data.csv") %>% 
  mutate(hours_noon = min_day / 60 - 12)
```

# Core model formulas

We will be focusing on models that include fixed effect for the experimental 
manipulations and for site, as well as a continuous time-of-day variable to 
capture variation in bee activity associated with diurnal patterns.
We modeled variation among days (e.g. due to differences in recent weather 
events) and among individual plants using random effects. Because the number
of sites (3) was too small to estimate site-to-site variance, we treated `Site` 
as a fixed effect.

While additional variables were recorded during sampling, their primary purpose
was to keep the sampling effort focused on a narrow range of environmental 
conditions (because environmental effects such as humidity were not related to
our primary hypotheses). We thus did not expect these variables to vary enough
in our samples to substantially affect the results, and did not include them
in most of our analyses. In the final section of this Appendix, we show that
the exclusion of these variables (and of a continuous measure of seasonality) 
do not affect the statistical significance or point estimates associated with
any treatment effects, and that they do not significantly improve model fit in 
terms of $\chi^2$ or AIC.

```{r}
raw_formula = "Bee_Count ~ Mold * Insecticide + 
                           Sugar * Paint + 
                           hours_noon + 
                           Site +
                           (1|Plant_Code) + 
                           (1|julDate)"

formula = as.formula(raw_formula)
```

We also fit a model that did not include sugar as a predictor variable, to 
assess whether its inclusion substantially improves our ability to predict bee
density. 

```{r}
# Drop "Sugar" and the asterisk from the formula
no_sugar_formula = as.formula(
  gsub("Sugar \\* ", "", raw_formula)
)

print(no_sugar_formula)
```

# Model fitting

We modeled the bee counts with negative binomial and Poisson mixed models with
the default log link.

```{r, cache = TRUE}
# Some versions of the model only reach the maximum-likelihood
# estimate without warnings when we use this optimizer
control = glmerControl(optimizer = "bobyqa")

Honeydew <- glmer.nb(
  formula,
  data=d,
  control = control
)


Honeydew_poisson <- glmer(
  formula,
  data=d,
  family = poisson,
  control = control
)

Honeydew_no_sugar <- glmer.nb(
  no_sugar_formula,
  data=d,
  control = control
)
```

# Model comparison

Which elements of the models fit above are essential? See what happens to model
performance (AIC) when various degrees of freedom are removed from the 
full `Honeydew` negative binomial model.

```{r}
# Drop predictors from the model & reformat the output for
# subsequent work (e.g. removing headings, renaming columns).
# When `drop` says the number of degrees of freedom is NA, it actually 
# means zero, so replace the NAs.
# If the model in `x` is already simplified, then report a larger
# reduction in degrees-of-freedom.
make_dropped_df = function(x, distribution, n_fewer_df = 0){
  drop1(x) %>% 
    structure(heading = NULL) %>% 
    rownames_to_column(var = "dropped") %>% 
    cbind(distribution = distribution) %>% 
    mutate(Df = ifelse(is.na(Df), 0, Df)) %>% 
    mutate(Df = Df + n_fewer_df) %>% 
    rename_(`df reduction` = "Df")
}

# Use the above function on both of the full models, then manually add
# a row for the no_sugar model.
# Finally, eliminate "<" and ">" to prevent formatting errors
initial_dropped_df = rbind(make_dropped_df(Honeydew, "Negative Binomial", 0), 
                           make_dropped_df(Honeydew_poisson, "Poisson", 1)) %>% 
  rbind(data_frame(dropped = "Sugar", `df reduction` = 2, 
                   AIC = AIC(Honeydew_no_sugar), 
                   distribution = "Negative Binomial")) %>% 
  mutate(dropped = gsub("[\\<\\>]", "", dropped))
```

Omitting site or either of the interaction terms (lines 1, 2, 4 and 5) produces 
a relatively small change in AIC, compared with the full model (line 3). However,
none of the models without overdispersion (i.e. the Poisson-distributed models)
had any appreciable AIC weight, nor did the model that removed all sugar effects 
(line 10).

```{r}
# Sort, calculate DeltaAIC & AIC weights, format for printing with 
# reasonable precision using knitr's `kable` function for tables.
initial_dropped_df %>% 
  arrange(AIC) %>% 
  mutate(`$\\Delta$AIC` = AIC - AIC[1]) %>% 
  select(-AIC) %>% 
  mutate(`AIC weight (%)` = 100 * exp(-`$\\Delta$AIC` / 2) / 
           sum(exp(-`$\\Delta$AIC` / 2))) %>% 
  cbind(` ` = 1:nrow(.), .) %>% 
  knitr::kable(digits = c(rep(1, 4), 2, 1), align = c("llclrr"))
```

$\chi^2$ tests show the same result: omitting sugar effects or overdispersion
significantly reduces model performance (P < .000001).
```{r}
anova(Honeydew, Honeydew_no_sugar)
anova(Honeydew, Honeydew_poisson)
```


# Description of the full `Honeydew` model
```{r}
summary(Honeydew, correlation = FALSE)
anova(Honeydew)
```

# Monte Carlo comparison of treatment effects

```{r, fig.height=6, fig.width=6, dev="png", dpi=300}
# Indicator for, "was experimental manipulation i applied to treatment j?""
Mold =        c(1, 1, 0, 0, 0, 0, 0)
Insecticide = c(0, 1, 0, 1, 0, 0, 0)
Sugar =       c(0, 0, 0, 0, 0, 1, 1)
Paint =       c(0, 0, 0, 0, 1, 0, 1)

treat_names = c("Natural Mold", "Natural Mold + Insecticide", "Control", 
                "Insecticide", "Black Paint", "Sugar", "Sugar + Black Paint")

# Ask the model about expected visitation rates under the
# following conditions:
#   * Treatments as specified above
#   * Time of day is noon
#   * Site A (i.e. SiteB and SiteC are 0)
#   * "Typical" plant and "typical" date (random effects set to 0)
newdata = cbind(
  `(Intercept)` = 1,
  Mold = Mold,
  Insecticide = Insecticide,
  Sugar = Sugar,
  Paint = Paint,
  hours_noon = 0,
  SiteB = 0,
  SiteC = 0,
  `Mold:Insecticide` = Mold * Insecticide,
  `Sugar:Paint` = Sugar * Paint
)
row.names(newdata) = treat_names
newdata


# mean and variance from lme4's Laplace approximation
parameter_mu = fixef(Honeydew)
parameter_sigma = as.matrix(vcov(Honeydew))

# Generate Monte Carlo samples from lme4's approximate likelihood surface
posterior_samples = rmvnorm(1E6, parameter_mu, parameter_sigma) %*%
  t(newdata)

mu = colMeans(posterior_samples)

# Density of bivariate normal between Control and a named treatment
bivariate_normal_control_density = function(x, name){
  names = c("Control", name)
  dmvnorm(x, 
          mu[names], 
          cov(posterior_samples)[names, names])
}

label_df = data.frame(
  x = c(rep(log(.05), 3)),
  y = c(mu[c("Sugar", "Natural Mold", "Natural Mold + Insecticide")] - 0.25),
  label = c("Sugar", "Natural Mold", "Natural Mold +\nInsecticide")
)
line_df = data.frame(x = log(.025), y = log(.02), 
                     label = "Treatment = Control")

# for each set of x and y values, calculate bivariate densities,
# then tidy up the results for ggplot (with an optional `theme` for
# improved visual display)
plot_data = expand.grid(x = seq(log(.01), log(1), length = 250), 
            y = seq(log(.01), log(6), length = 250)) %>% 
  mutate(Sugar = bivariate_normal_control_density(., "Sugar"),
         `Natural Mold` = bivariate_normal_control_density(., "Natural Mold"),
         `Natural Mold + Insecticide` = 
           bivariate_normal_control_density(., "Natural Mold + Insecticide")) %>% 
  gather(key = treatment, value = likelihood, Sugar, 
         `Natural Mold`, `Natural Mold + Insecticide`) %>% 
  mutate(scaled_likelihood = likelihood / max(likelihood))

plot_data %>% 
  ggplot(aes(x = x, y = y, alpha = scaled_likelihood, 
             fill = treatment)) + 
  geom_tile() +
  scale_alpha_continuous(range = c(0, 1), guide = FALSE) + 
  geom_abline(intercept = 0, slope = 1, color = alpha("black", .5)) +
  cowplot::theme_cowplot() +
  scale_fill_brewer(palette = "Dark2", guide = FALSE) + 
  xlab("Expected bees per control plant") +
  ylab("Expected bees per treated plant") + 
  coord_equal() +
  scale_x_continuous(breaks = log(10^seq(-10, 10)), labels = 10^seq(-10, 10),
                     expand = c(0, 0)) +
  scale_y_continuous(breaks = log(10^seq(-10, 10)), labels = 10^seq(-10, 10),
                     expand = c(0, 0)) +
  geom_text(data = label_df, aes(x = x, y = y, label = label),
            inherit.aes = FALSE, hjust = "right") + 
  geom_text(data = line_df, aes(x = x, y = y, label = label), 
            inherit.aes = FALSE, hjust = "left")


```

# Post-hoc comparisons between specific treatment pairs

```{r}
names = names(sort(colMeans(posterior_samples), decreasing = TRUE))
grid = combn(names, 2) %>% t() %>% as.data.frame(stringsAsFactors = FALSE)
grid$P = NA
for (i in 1:nrow(grid)) {
  # One-sided P-values
  p = mean(posterior_samples[ , grid[[1]][i]] > posterior_samples[ , grid[[2]][i]])
  
  # Two-sided P-values
  grid$P[i] = 1 - 2 * abs(0.5 - p)
}

table = grid %>% 
  mutate(`False Discovery Rate` = p.adjust(P, method = "fdr")) 
```

Significance and False Discovery Rates for selected post-hoc comparisons between
treatments. The false discovery rate is a way to correct for multiple comparisons
without sacrificing too much statistical power. See `?p.adjust` and references
therein.

```{r}
table %>% filter((V1 == "Sugar" & V2 == "Natural Mold") |
                   (V1 == "Natural Mold" & V2 == "Control") |
                   (V1 == "Natural Mold" &  V2 == "Natural Mold + Insecticide") |
                   (V1 == "Sugar" & V2 == "Sugar + Black Paint")) %>% 
  knitr::kable(digits = 3)
```


Significance and False Discovery Rates for all pairwise comparisons among
experimental treatments.

```{r}
table %>% 
  knitr::kable(digits = 3)
```



# Comparing to a model with environmental predictors & continuous dates

We could have obtained essentially the same results with a much larger model that 
included a fixed effect for date and environmental conditions (i.e., there would
still be a significant sugar effect with point estimate $\approx$ 2.4, 
a significant mold effect with point estimate $\approx$ 1.2, and a significant 
mold/insecticide interaction with point estimate $\approx$ -1.5). 

However, the eight degrees of freedom associated with environmental conditions
and the fixed effect for date do not improve the model fit enough to 
justify the additional complexity ($\chi^2$ > 0.25, higher AIC), so we disregard
them outide of this section.

```{r, cache = TRUE}
# rescaling variables that have large values using `scale` improves numerical 
# accuracy, but will not affect AIC.
Honeydew_env = glmer.nb(Bee_Count ~ Mold * Insecticide + 
                          Sugar * Paint + 
                          Site + 
                          hours_noon + 
                          scale(Temp_F) + 
                          scale(Wind_mph) + 
                          Conditions + 
                          scale(Barometric) +
                          scale(Humidity) + 
                          scale(julDate) +
                          (1|Plant_Code) + 
                          (1|julDate), 
                        data = d, 
                        control = control)
print(summary(Honeydew_env), correlation = FALSE)
anova(Honeydew, Honeydew_env)
```
